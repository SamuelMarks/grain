diff --git a/cpp/array_record_reader.cc b/cpp/array_record_reader.cc
index bc7675e..623911a 100644
--- a/cpp/array_record_reader.cc
+++ b/cpp/array_record_reader.cc
@@ -196,7 +196,7 @@ void ArrayRecordReaderBase::Initialize() {
     max_parallelism = state_->pool->NumThreads();
     if (state_->options.max_parallelism().has_value()) {
       max_parallelism =
-          std::min(max_parallelism, state_->options.max_parallelism().value());
+          std::min<uint32_t>(max_parallelism, state_->options.max_parallelism().value());
     }
   }
   state_->options.set_max_parallelism(max_parallelism);
@@ -331,7 +331,7 @@ absl::Status ArrayRecordReaderBase::ParallelReadRecords(
     return absl::OkStatus();
   }
   uint64_t num_chunk_groups =
-      CeilOfRatio(state_->chunk_offsets.size(), state_->chunk_group_size);
+      CeilOfRatio<uint64_t>(state_->chunk_offsets.size(), state_->chunk_group_size);
   const auto reader = get_backing_reader();
   Reader* mutable_reader = const_cast<Reader*>(
       reinterpret_cast<const Reader*>(reader.get()));
@@ -340,7 +340,7 @@ absl::Status ArrayRecordReaderBase::ParallelReadRecords(
         uint64_t chunk_idx_start = buf_idx * state_->chunk_group_size;
         // inclusive index, not the conventional exclusive index.
         uint64_t last_chunk_idx =
-            std::min((buf_idx + 1) * state_->chunk_group_size - 1,
+            std::min<uint64_t>((buf_idx + 1) * state_->chunk_group_size - 1,
                      state_->chunk_offsets.size() - 1);
         uint64_t buf_len = state_->ChunkEndOffset(last_chunk_idx) -
                            state_->chunk_offsets[chunk_idx_start];
@@ -406,9 +406,9 @@ absl::Status ArrayRecordReaderBase::ParallelReadRecordsInRange(
         "Invalid range [%d, %d). Total records: %d", begin, end, NumRecords()));
   }
   uint64_t chunk_idx_begin = begin / state_->record_group_size;
-  uint64_t chunk_idx_end = CeilOfRatio(end, state_->record_group_size);
+  uint64_t chunk_idx_end = CeilOfRatio<uint64_t>(end, state_->record_group_size);
   uint64_t num_chunks = chunk_idx_end - chunk_idx_begin;
-  uint64_t num_chunk_groups = CeilOfRatio(num_chunks, state_->chunk_group_size);
+  uint64_t num_chunk_groups = CeilOfRatio<uint64_t>(num_chunks, state_->chunk_group_size);
 
   const auto reader = get_backing_reader();
   Reader* mutable_reader =
@@ -418,7 +418,7 @@ absl::Status ArrayRecordReaderBase::ParallelReadRecordsInRange(
         uint64_t chunk_idx_start =
             chunk_idx_begin + buf_idx * state_->chunk_group_size;
         // inclusive index, not the conventional exclusive index.
-        uint64_t last_chunk_idx = std::min(
+        uint64_t last_chunk_idx = std::min<uint64_t>(
             chunk_idx_begin + (buf_idx + 1) * state_->chunk_group_size - 1,
             chunk_idx_end - 1);
         uint64_t buf_len = state_->ChunkEndOffset(last_chunk_idx) -
@@ -617,7 +617,7 @@ bool ArrayRecordReaderBase::SeekRecord(uint64_t record_index) {
   if (!ok()) {
     return false;
   }
-  state_->record_idx = std::min(record_index, state_->num_records);
+  state_->record_idx = std::min<uint64_t>(record_index, state_->num_records);
   return true;
 }
 
@@ -667,7 +667,7 @@ bool ArrayRecordReaderBase::ReadAheadFromBuffer(uint64_t buffer_idx) {
     std::vector<ChunkDecoder> decoders;
     decoders.reserve(state_->chunk_group_size);
     uint64_t chunk_start = buffer_idx * state_->chunk_group_size;
-    uint64_t chunk_end = std::min(state_->chunk_offsets.size(),
+    uint64_t chunk_end = std::min<uint64_t>(state_->chunk_offsets.size(),
                                   (buffer_idx + 1) * state_->chunk_group_size);
     const auto reader = get_backing_reader();
     for (uint64_t chunk_idx = chunk_start; chunk_idx < chunk_end; ++chunk_idx) {
@@ -708,7 +708,7 @@ bool ArrayRecordReaderBase::ReadAheadFromBuffer(uint64_t buffer_idx) {
     chunk_offsets.reserve(state_->chunk_group_size);
     uint64_t chunk_start = buffer_to_add * state_->chunk_group_size;
     uint64_t chunk_end =
-        std::min(state_->chunk_offsets.size(),
+        std::min<uint64_t>(state_->chunk_offsets.size(),
                  (buffer_to_add + 1) * state_->chunk_group_size);
     for (uint64_t chunk_idx = chunk_start; chunk_idx < chunk_end; ++chunk_idx) {
       chunk_offsets.push_back(state_->chunk_offsets[chunk_idx]);
